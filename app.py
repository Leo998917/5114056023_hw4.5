import streamlit as st
import sqlite3
import pandas as pd
import json
import requests
import os

# ==========================================
# åŸæœ¬ cwa_crawler.py çš„å…§å®¹ (ç›´æ¥è²¼åœ¨é€™è£¡)
# ==========================================

DB_NAME = "data.db"
JSON_FILE = "F-A0010-001.json"
API_URL = "https://opendata.cwa.gov.tw/fileapi/v1/opendataapi/F-A0010-001"

def get_weather_data(api_key=None):
    # ... (é€™è£¡æ”¾åŸæœ¬ crawler çš„ get_weather_data å‡½å¼å…§å®¹) ...
    # ç‚ºäº†ç¯€çœç¯‡å¹…ï¼Œè«‹æŠŠ cwa_crawler.py çš„ get_weather_data æ•´æ®µè¤‡è£½éä¾†
    if os.path.exists(JSON_FILE):
        with open(JSON_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    elif api_key:
        params = {"Authorization": api_key, "downloadType": "WEB", "format": "JSON"}
        response = requests.get(API_URL, params=params)
        if response.status_code == 200:
            data = response.json()
            with open(JSON_FILE, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=4)
            return data
    return None

def parse_and_save_to_db(data):
    # ... (é€™è£¡æ”¾åŸæœ¬ crawler çš„ parse_and_save_to_db å‡½å¼å…§å®¹) ...
    # è«‹æŠŠ cwa_crawler.py çš„ parse_and_save_to_db æ•´æ®µè¤‡è£½éä¾†
    if not data: return
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    cursor.execute("DROP TABLE IF EXISTS weather")
    cursor.execute("""
        CREATE TABLE weather (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            location TEXT, min_temp TEXT, max_temp TEXT, description TEXT
        )
    """)
    try:
        locations = data['cwaopendata']['dataset']['location']
        insert_list = []
        for loc in locations:
            city_name = loc['locationName']
            wx, min_t, max_t = "N/A", "N/A", "N/A"
            for elem in loc['weatherElement']:
                elem_name = elem['elementName']
                first_val = elem['time'][0]['parameter']['parameterName']
                if elem_name == 'Wx': wx = first_val
                elif elem_name == 'MinT': min_t = first_val
                elif elem_name == 'MaxT': max_t = first_val
            insert_list.append((city_name, min_t, max_t, wx))
        cursor.executemany("INSERT INTO weather (location, min_temp, max_temp, description) VALUES (?, ?, ?, ?)", insert_list)
        conn.commit()
    except Exception as e:
        print(e)
    finally:
        conn.close()

# ==========================================
# åŸæœ¬ app.py çš„ Streamlit ä»‹é¢ç¨‹å¼ç¢¼
# ==========================================

st.set_page_config(page_title="å°ç£å¤©æ°£é å ± Dashboard", page_icon="ğŸŒ¦ï¸")
st.title("ğŸŒ¦ï¸ å°ç£å„ç¸£å¸‚å¤©æ°£é å ± (CWA)")

st.sidebar.header("åŠŸèƒ½é¸å–®")

# API Key è™•ç†
if "cwa" in st.secrets:
    api_key = st.secrets["cwa"]["api_key"]
    st.sidebar.success("API Key å·²è¼‰å…¥ âœ…")
else:
    api_key = st.sidebar.text_input("è«‹è¼¸å…¥ CWA API Key", type="password")

if st.sidebar.button("ğŸ”„ æ›´æ–°/é‡æŠ“ è³‡æ–™åº«"):
    if not api_key:
        st.error("è«‹å…ˆè¨­å®š API Keyï¼")
    else:
        with st.spinner("æ›´æ–°ä¸­..."):
            # ç›´æ¥å‘¼å«ä¸Šé¢å®šç¾©å¥½çš„å‡½å¼ï¼Œä¸ç”¨ cwa_crawler. äº†
            raw_data = get_weather_data(api_key)
            parse_and_save_to_db(raw_data)
            st.success("å®Œæˆï¼")
            st.rerun()

# è®€å– DB é¡¯ç¤º
if os.path.exists(DB_NAME):
    conn = sqlite3.connect(DB_NAME)
    df = pd.read_sql("SELECT * FROM weather", conn)
    conn.close()
    
    if not df.empty:
        st.dataframe(df[['location', 'min_temp', 'max_temp', 'description']], use_container_width=True)
    else:
        st.warning("è³‡æ–™åº«æ˜¯ç©ºçš„")
else:
    st.info("å°šæœªå»ºç«‹è³‡æ–™åº«ï¼Œè«‹é»æ“Šå·¦å´æ›´æ–°æŒ‰éˆ•")