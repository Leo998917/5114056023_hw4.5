import streamlit as st
import google.generativeai as genai
import PIL.Image

# 1. ç‰ˆé¢è¨­å®š
st.set_page_config(page_title="Gemini Chat", layout="centered")

# 2. å®‰å…¨æ€§æª¢æŸ¥
api_key = st.secrets.get("GOOGLE_API_KEY")
if not api_key:
    st.error("âŒ éŒ¯èª¤ï¼šæœªåµæ¸¬åˆ° API Keyã€‚è«‹æª¢æŸ¥ .streamlit/secrets.toml æ˜¯å¦å·²å»ºç«‹ã€‚")
    st.stop()

# 3. è¨­å®š Gemini
genai.configure(api_key=api_key)

# 4. è‡ªå‹•åµæ¸¬å¯ç”¨æ¨¡å‹ (é—œéµä¿®æ­£ï¼šä¸å†æ‰‹å‹•å¯«æ­»åç¨±)
try:
    # æ‰¾å‡ºæ‰€æœ‰æ”¯æ´ 'generateContent' çš„æ¨¡å‹
    available_models = [m for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    if not available_models:
        st.error("âŒ æ‚¨çš„ API Key æ²’æœ‰å¯ç”¨çš„æ¨¡å‹æ¬Šé™ã€‚")
        st.stop()
    
    # ç›´æ¥é¸ç”¨åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹æ¨¡å‹ (é€šå¸¸æ˜¯ gemini-1.5-flash æˆ– gemini-pro)
    # é€™æ¨£åšä¿è­‰æ¨¡å‹åç¨±çµ•å°æ­£ç¢ºï¼Œå› ç‚ºæ˜¯ API è‡ªå·±å‘Šè¨´æˆ‘å€‘çš„
    target_model_name = available_models[0].name
    
except Exception as e:
    st.error(f"âŒ ç„¡æ³•å–å¾—æ¨¡å‹æ¸…å–®ï¼Œè«‹æª¢æŸ¥ API Key æˆ–ç¶²è·¯é€£ç·šï¼š{e}")
    st.stop()

# 5. å´é‚Šæ¬„è¨­å®š
with st.sidebar:
    st.title("ğŸ”§ è¨­å®š")
    # é¡¯ç¤ºç›®å‰è‡ªå‹•é¸åˆ°çš„æ¨¡å‹ï¼Œè®“ä½ å¿ƒè£¡æœ‰æ•¸
    st.caption(f"ç›®å‰ä½¿ç”¨æ¨¡å‹ï¼š`{target_model_name}`")
    
    system_instruction = st.text_area(
        "ç³»çµ±æŒ‡ä»¤ (System Instruction)", 
        value="ä½ æ˜¯ä¸€å€‹ç¹é«”ä¸­æ–‡çš„ AI åŠ©æ‰‹ï¼Œå›ç­”è«‹ç°¡æ½”æœ‰åŠ›ã€‚",
        height=150
    )
    
    # åœ–ç‰‡ä¸Šå‚³åŠŸèƒ½
    uploaded_file = st.file_uploader("ğŸ“¸ ä¸Šå‚³åœ–ç‰‡ (å¯é¸)", type=['jpg', 'png', 'jpeg'])
    img = None
    if uploaded_file:
        img = PIL.Image.open(uploaded_file)
        st.image(img, caption="å·²ä¸Šå‚³åœ–ç‰‡", use_column_width=True)

    if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±"):
        st.session_state.messages = []
        st.rerun()

# 6. ç‹€æ…‹ç®¡ç†
if "messages" not in st.session_state:
    st.session_state.messages = []

# 7. é¡¯ç¤ºæ­·å²è¨Šæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "image" in message:
            st.image(message["image"])

# 8. è™•ç†è¼¸å…¥èˆ‡å›æ‡‰
if prompt := st.chat_input("è¼¸å…¥ä½ çš„å•é¡Œ..."):
    # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
        if img:
            st.image(img)
    
    user_msg = {"role": "user", "content": prompt}
    if img:
        user_msg["image"] = img
    st.session_state.messages.append(user_msg)

    # å‘¼å« Gemini
    try:
        # åˆå§‹åŒ–æ¨¡å‹ (åŠ å…¥ system_instruction)
        model = genai.GenerativeModel(
            target_model_name, 
            system_instruction=system_instruction
        )
        
        # è½‰æ›æ­·å²ç´€éŒ„æ ¼å¼
        gemini_history = []
        for m in st.session_state.messages[:-1]:
            role = "user" if m["role"] == "user" else "model"
            parts = [m["content"]]
            if "image" in m:
                parts.append(m["image"])
            gemini_history.append({"role": role, "parts": parts})
        
        chat = model.start_chat(history=gemini_history)
        
        # é¡¯ç¤º AI æ€è€ƒä¸­çš„ç‹€æ…‹
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            with st.spinner(f"Gemini ({target_model_name}) æ­£åœ¨æ€è€ƒ..."):
                # åˆ¤æ–·æ˜¯å¦åŒ…å«åœ–ç‰‡å‚³é€
                if img:
                    response = chat.send_message([prompt, img])
                else:
                    response = chat.send_message(prompt)
                response_placeholder.markdown(response.text)
        
        st.session_state.messages.append({"role": "assistant", "content": response.text})

    except Exception as e:
        st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")