import requests
from bs4 import BeautifulSoup
import time
import random

# è¨­å®šç›®æ¨™ç¶²ç«™åŸºç¤ç¶²å€
BASE_URL = "https://ssr1.scrape.center/page/{}"

def fetch_page(page_number):
    """çˆ¬å–å–®ä¸€é é¢çš„ HTML"""
    url = BASE_URL.format(page_number)
    print(f"ğŸ“¥ æ­£åœ¨çˆ¬å–ç¬¬ {page_number} é : {url}")
    
    try:
        # verify=False é˜²æ­¢ SSL éŒ¯èª¤
        response = requests.get(url, verify=False) 
        if response.status_code == 200:
            return response.text
        else:
            return None
    except Exception as e:
        print(f"âŒ é€£ç·šç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def parse_html(html):
    """è§£æ HTML ä¸¦æå–é›»å½±è³‡è¨Š"""
    soup = BeautifulSoup(html, "html.parser")
    movies = []
    
    items = soup.find_all(class_="el-card")
    
    for item in items:
        try:
            # 1. é›»å½±åç¨±
            title_tag = item.find("h2")
            title = title_tag.text.strip() if title_tag else "N/A"
            
            # 2. åœ–ç‰‡ URL
            img_tag = item.find("img", class_="cover")
            cover_url = img_tag["src"] if img_tag else "N/A"
            
            # 3. è©•åˆ†
            score_tag = item.find(class_="score")
            score = score_tag.text.strip() if score_tag else "N/A"
            
            # 4. é¡å‹
            categories_tag = item.find(class_="categories")
            if categories_tag:
                cats = [btn.text.strip() for btn in categories_tag.find_all("button")]
                category = ", ".join(cats)
            else:
                category = "N/A"
            
            movie_data = {
                "Title": title,
                "Cover URL": cover_url,
                "Score": score,
                "Category": category
            }
            movies.append(movie_data)
            
        except Exception as e:
            continue
            
    return movies